{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import utilities\n",
    "import json\n",
    "\n",
    "from py2neo import Graph\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrisolen/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (2,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "cols = ['year',\n",
    " 'abi',\n",
    " 'ticker',\n",
    " 'company',\n",
    " 'address_line_1',\n",
    " 'city',\n",
    " 'zipcode',\n",
    " 'location_employee_size_code',\n",
    " 'location_sales_volume_code',\n",
    " 'primary_naics_code',\n",
    " 'sic_code',\n",
    " 'sic6_descriptions_sic',\n",
    " 'business_status_code',\n",
    " 'office_size_code',\n",
    " 'company_holding_status',\n",
    " 'parent_employee_size_code',\n",
    " 'parent_sales_volume_code',\n",
    " 'census_tract',\n",
    " 'cbsa_code',\n",
    " 'year_established',\n",
    " 'employee_size_location',\n",
    " 'sales_volume_location',\n",
    " 'parent_actual_employee_size',\n",
    " 'parent_actual_sales_volume',\n",
    " 'latitude',\n",
    " 'longitude']\n",
    "\n",
    "bus = pd.read_csv(\"../data/chi_bus.csv\", sep='\\t', names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1144876, 26)"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering for useful features\n",
    "\n",
    "bus = bus[['abi','primary_naics_code','company','year','business_status_code','company_holding_status','census_tract','year_established',\n",
    "    'employee_size_location','sales_volume_location',\n",
    "    'latitude','longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    1034553\n",
       "2     101871\n",
       "3       4241\n",
       "1       4211\n",
       "Name: business_status_code, dtype: int64"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# understanding business status code\n",
    "\n",
    "\"\"\"\n",
    "Business Status Code:\n",
    "\n",
    "1: Headquarter\n",
    "2: Branch\n",
    "3: Subsidiary\n",
    "9: Single Location\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "bus['business_status_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1144164\n",
       "False        712\n",
       "Name: company_holding_status, dtype: int64"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# understanding business status holding\n",
    "\n",
    "\"\"\"\n",
    "Business Status Holding:\n",
    "\n",
    "I'm gonna assume the 712 are publicly traded and the others aren't?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "bus['company_holding_status'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1144164\n",
       "False        712\n",
       "Name: company_holding_status, dtype: int64"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# understanding company holding status\n",
    "\n",
    "bus['company_holding_status'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1143647\n",
       "True        1229\n",
       "Name: primary_naics_code, dtype: int64"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus['primary_naics_code'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove naics code nulls and convert to string\n",
    "\n",
    "bus = bus[~bus['primary_naics_code'].isna()]\n",
    "bus['primary_naics_code'] = (bus['primary_naics_code'].astype(int)).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering for naics codes\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "NAICS CODE 445110: Supermarkets and Other Grocery (except Convenience)\n",
    "NAICS CODE 447110: Gasoline Stations with Convenience Stores\n",
    "NAICS CODE 445120: Convenience Stores\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "groc = bus[(bus['primary_naics_code'].str.contains('445110')) | (bus['primary_naics_code'].str.contains('447110')) | (bus['primary_naics_code'].str.contains('445120'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14851, 12)"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013    1985\n",
       "2014    1808\n",
       "2012    1706\n",
       "2015    1623\n",
       "2009    1602\n",
       "2010    1591\n",
       "2011    1575\n",
       "2016    1391\n",
       "2017    1187\n",
       "2018     383\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# understanding year distribution \n",
    "\n",
    "groc['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering for 2016 and 2017\n",
    "\n",
    "groc_2016 = groc[groc['year']==2016]\n",
    "groc_2017 = groc[groc['year']==2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = pd.merge(left=groc_2017, right=groc_2016, left_on='abi', right_on='abi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1112, 23)"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand.drop(['primary_naics_code_y','company_y','year_y','business_status_code_y',\n",
    "            'company_holding_status_y','census_tract_y','year_established_y',\n",
    "            'company_y','year_y','business_status_code_y',\n",
    "            'latitude_y','longitude_y'], inplace=True, axis=1)\n",
    "\n",
    "cols = [demand.columns[i].replace(\"_x\",\"_2017\").replace(\"_y\",\"_2016\") for i in range(len(demand.columns))]\n",
    "replacing = {i:j for (i,j) in zip(demand.columns,cols)}\n",
    "demand.rename(columns=replacing, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to graph db\n",
    "\n",
    "uri = \"bolt://localhost:7687\"\n",
    "graph = Graph(uri, auth=(\"neo4j\", \"password\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling out coordinates for each store\n",
    "\n",
    "coordinates = list(zip(demand[\"longitude_2017\"],demand[\"latitude_2017\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dicts/neighborhood_polys.json','r') as f:\n",
    "    neighborhoods = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrisolen/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# laoding average property value for the neighborhood in which the stores is located\n",
    "\n",
    "demand['neighborhood_avg_property_value'] = np.nan\n",
    "\n",
    "outside_city = []\n",
    "\n",
    "for i in range(len(coordinates)):\n",
    "\n",
    "    point_district = utilities.point_lookup(neighborhoods,coordinates[i])\n",
    "    \n",
    "    try:\n",
    "        result = float(dict(pd.DataFrame(graph.run('match (a:neighborhood) where a.name = \"{}\" return a'.format(point_district)). \\\n",
    "                            to_table()).iloc[0,0])['avg_property_value'])\n",
    "    except:\n",
    "        outside_city.append((i, coordinates[i]))\n",
    "        pass\n",
    "     \n",
    "    ## coordinates and df indices should be the same ## \n",
    "    demand['neighborhood_avg_property_value'].iloc[i] = result\n",
    "    \n",
    "for i in range(len(outside_city)): # for the few coordinates that lie just outside the city\n",
    "    \n",
    "    point_district = utilities.closest_to(neighborhoods,outside_city[i][1])\n",
    "    \n",
    "    result = float(dict(pd.DataFrame(graph.run('match (a:neighborhood) where a.name = \"{}\" return a'.format(point_district)). \\\n",
    "                            to_table()).iloc[0,0])['avg_property_value'])\n",
    "    \n",
    "    \n",
    "    demand['neighborhood_avg_property_value'].iloc[outside_city[i][0]] = result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading number of property crimes per neighborhood into demand model for each store\n",
    "\n",
    "demand['neighborhood_property_crimes'] = np.nan\n",
    "\n",
    "outside_city = []\n",
    "\n",
    "for i in range(len(coordinates)):\n",
    "\n",
    "    point_district = utilities.point_lookup(neighborhoods,coordinates[i])\n",
    "    \n",
    "    try:\n",
    "        result = float(dict(pd.DataFrame(graph.run('match (a:neighborhood) where a.name = \"{}\" return a'.format(point_district)). \\\n",
    "                            to_table()).iloc[0,0])['n_property_crimes'])\n",
    "    except:\n",
    "        outside_city.append((i, coordinates[i]))\n",
    "        pass\n",
    "     \n",
    "    ## coordinates and df indices should be the same ## \n",
    "    demand['neighborhood_property_crimes'].iloc[i] = result\n",
    "    \n",
    "for i in range(len(outside_city)): # for the few coordinates that lie just outside the city\n",
    "    \n",
    "    point_district = utilities.closest_to(neighborhoods,outside_city[i][1])\n",
    "    \n",
    "    result = float(dict(pd.DataFrame(graph.run('match (a:neighborhood) where a.name = \"{}\" return a'.format(point_district)). \\\n",
    "                            to_table()).iloc[0,0])['n_property_crimes'])\n",
    "    \n",
    "    \n",
    "    demand['neighborhood_property_crimes'].iloc[outside_city[i][0]] = result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading average property values of neighborhoods surrounding the neighborhood of the given store\n",
    "\n",
    "demand['surrounding_neighborhood_avg_property_value'] = np.nan\n",
    "\n",
    "outside_city = []\n",
    "\n",
    "for i in range(len(coordinates)):\n",
    "\n",
    "    point_district = utilities.point_lookup(neighborhoods,coordinates[i])\n",
    "    \n",
    "    try:\n",
    "        result = pd.DataFrame(graph.run('match (a:neighborhood)-[:NEXT_TO]->(b) where a.name = \"{}\" return b'.format(point_district)). \\\n",
    "                            to_table())\n",
    "\n",
    "        n_next_door = len(result[0])\n",
    "\n",
    "        neighboring_means = []\n",
    "\n",
    "        for j in range(n_next_door):\n",
    "            neighboring_mean = float(dict(result[0][j])['avg_property_value'])\n",
    "            neighboring_means.append(neighboring_mean)\n",
    "            \n",
    "        surrounding_mean = np.nanmean(neighboring_means)\n",
    "            \n",
    "    except:\n",
    "        outside_city.append((i, coordinates[i]))\n",
    "     \n",
    "    ## coordinates and df indices should be the same ## \n",
    "    demand['surrounding_neighborhood_avg_property_value'].iloc[i] = surrounding_mean\n",
    "    \n",
    "for i in range(len(outside_city)): # for the few coordinates that lie just outside the city\n",
    "    \n",
    "    point_district = utilities.closest_to(neighborhoods,outside_city[i][1])\n",
    "    \n",
    "    result = pd.DataFrame(graph.run('match (a:neighborhood)-[:NEXT_TO]->(b) where a.name = \"{}\" return b'.format(point_district)). \\\n",
    "                            to_table())\n",
    "\n",
    "    n_next_door = len(result[0])\n",
    "\n",
    "    neighboring_means = []\n",
    "\n",
    "    for i in range(n_next_door):\n",
    "        neighboring_mean = float(dict(result[0][i])['avg_property_value'])\n",
    "        neighboring_means.append(neighboring_mean)\n",
    "        \n",
    "    surrounding_mean = np.nanmean(neighboring_means)\n",
    "    \n",
    "    demand['surrounding_neighborhood_avg_property_value'].iloc[outside_city[i][0]] = surrounding_mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading number of property crimes of neighborhoods surrounding the neighborhood of the given store\n",
    "\n",
    "demand['surrounding_neighborhood_property_crimes'] = np.nan\n",
    "\n",
    "outside_city = []\n",
    "\n",
    "for i in range(len(coordinates)):\n",
    "\n",
    "    point_district = utilities.point_lookup(neighborhoods,coordinates[i])\n",
    "\n",
    "    try:\n",
    "        result = pd.DataFrame(graph.run('match (a:neighborhood)-[:NEXT_TO]->(b) where a.name = \"{}\" return b'.format(point_district)). \\\n",
    "                            to_table())\n",
    "\n",
    "        n_next_door = len(result[0])\n",
    "\n",
    "        neighboring_means = []\n",
    "\n",
    "        for j in range(n_next_door):\n",
    "            neighboring_mean = float(dict(result[0][j])['n_property_crimes'])\n",
    "            neighboring_means.append(neighboring_mean)\n",
    "            \n",
    "        surrounding_mean = np.nanmean(neighboring_means)\n",
    "        \n",
    "        ## coordinates and df indices should be the same ## \n",
    "        demand['surrounding_neighborhood_property_crimes'].iloc[i] = surrounding_mean\n",
    "            \n",
    "    except:\n",
    "        outside_city.append((i, coordinates[i]))\n",
    "        \n",
    "    \n",
    "for i in range(len(outside_city)): # for the few coordinates that lie just outside the city\n",
    "    \n",
    "    point_district = utilities.closest_to(neighborhoods,outside_city[i][1])\n",
    "    \n",
    "    result = pd.DataFrame(graph.run('match (a:neighborhood)-[:NEXT_TO]->(b) where a.name = \"{}\" return b'.format(point_district)). \\\n",
    "                            to_table())\n",
    "\n",
    "    n_next_door = len(result[0])\n",
    "\n",
    "    neighboring_means = []\n",
    "\n",
    "    for i in range(n_next_door):\n",
    "        neighboring_mean = float(dict(result[0][i])['n_property_crimes'])\n",
    "        neighboring_means.append(neighboring_mean)\n",
    "        \n",
    "    surrounding_mean = np.nanmean(neighboring_means)\n",
    "    \n",
    "    demand['surrounding_neighborhood_property_crimes'].iloc[outside_city[i][0]] = surrounding_mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = demand[(demand['sales_volume_location_2017'].notna()) &\n",
    "               (demand['sales_volume_location_2016'].notna()) &\n",
    "               (demand['neighborhood_property_crimes'].notna()) &\n",
    "               (demand['neighborhood_avg_property_value'].notna()) &\n",
    "               (demand['surrounding_neighborhood_avg_property_value'].notna()) &\n",
    "               (demand['surrounding_neighborhood_property_crimes'].notna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(demand[[\"sales_volume_location_2016\",\"neighborhood_avg_property_value\",\n",
    "                     \"neighborhood_property_crimes\",\n",
    "           \"surrounding_neighborhood_avg_property_value\",\"surrounding_neighborhood_property_crimes\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(demand[\"sales_volume_location_2017\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.93421877, -0.01227086, -0.12626835, -0.01550418,  0.12616219])"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316.22113961802916"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand.to_csv(\"demand.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
