{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/chrisolen/Documents/uchicago_courses/optimization/project/urban-demand-allocation')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from py2neo import Graph\n",
    "\n",
    "import utilities\n",
    "\n",
    "from optimizer.optimization_var_utils import sample_addresses, generate_distance_matrix, graph_to_address_frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in store-level data from the demand model\n",
    "demand_model = pd.read_csv(\"../demand_models/demand_model.csv\")\n",
    "\n",
    "# pull in all addresses\n",
    "addresses = pd.read_csv(\"../../data/address_book.csv\")\n",
    "\n",
    "# pull in locality shapefiles\n",
    "with open('../../data/geo_shape_files/neighborhood_reformatted.json','r') as f:\n",
    "    neighborhoods = json.load(f)\n",
    "    \n",
    "# connect to graph db\n",
    "uri = \"bolt://localhost:7687\"\n",
    "graph = Graph(uri, auth=(\"neo4j\", \"password\"))    \n",
    "\n",
    "# load in betas from demand model\n",
    "with open('optimization_variables/demand_betas.txt', 'r') as demand_betas:\n",
    "    betas = demand_betas.readlines()\n",
    "betas = np.array([float(betas[1].split(\",\")[i].replace(\"]\",\"\").replace(\"[\",\"\").replace(\"\\n\",\"\")) for i in range(len(betas[1].split(\",\")))])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrisolen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# take a random sample from the address book \n",
    "address_sample = sample_addresses(addresses, neighborhoods, \"neighborhood\", sample_size=10000)\n",
    "\n",
    "# update sample of addresses with socioeconomic data\n",
    "address_matrix = graph_to_opt_matrix(graph, address_sample, \"zestimate\", neighborhoods, \"neighborhood\")\n",
    "address_matrix = graph_to_opt_matrix(graph, address_matrix, \"primary_type\", neighborhoods, \"neighborhood\")\n",
    "address_matrix = graph_to_opt_matrix(graph, address_matrix, \"zestimate\", neighborhoods, \"neighborhood\", edge_relation=\"NEXT_TO\")\n",
    "address_matrix = graph_to_opt_matrix(graph, address_matrix, \"primary_type\", neighborhoods, \"neighborhood\", edge_relation=\"NEXT_TO\")\n",
    "\n",
    "# remove any rows with nans\n",
    "address_matrix.dropna(inplace=True)\n",
    "\n",
    "# generate euclidean distances from each address to each store address\n",
    "distance_matrix = generate_distance_matrix(address_matrix, demand_model)\n",
    "\n",
    "# drop unnecessary features \n",
    "address_matrix.drop(['ADDRDELIV', 'LATITUDE', 'LONGITUDE', 'neighborhood'], axis=1, inplace=True)\n",
    "\n",
    "# pull out most recdnt annual sales features\n",
    "sales = demand_model['sales_volume_location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing l2 norms to csv\n",
    "\n",
    "distance_weighted_sales_norm = np.linalg.norm(np.matmul(np.transpose(sales), distance_matrix))\n",
    "demand_beta_weighted_norm = np.linalg.norm(np.matmul(betas,np.transpose(np.array(address_matrix))))\n",
    "dic = {\"distance_weighted_sales_norm\":[distance_weighted_sales_norm],\"demand_beta_weighted_norm\":[demand_beta_weighted_norm]}\n",
    "norms = pd.DataFrame(dic)\n",
    "norms.to_csv(\"optimization_variables/norms.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing final demand model to csv\n",
    "\n",
    "demand_model.drop(['latitude','longitude','sales_volume_location_2016','sales_volume_location_2015'], axis=1, inplace=True)\n",
    "demand_model = np.array(demand_model)\n",
    "np.savetxt('optimization_variables/store_matrix2.csv', demand_model, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing final address matrix to csv\n",
    "\n",
    "address_matrix = np.array(address_matrix)\n",
    "np.savetxt('optimization_variables/address_matrix.csv', address_matrix1, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing final distance matrix to csv\n",
    "\n",
    "np.savetxt('optimization_variables/distance_matrix.csv', distance_matrix, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
