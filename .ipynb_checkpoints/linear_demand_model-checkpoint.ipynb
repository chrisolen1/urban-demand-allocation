{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'demand_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-235-b0eb7fcc28d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdemand_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfilter_business_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'demand_models'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from py2neo import Graph\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import utilities\n",
    "from demand_models import filter_business_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_types = pd.read_csv('../data/dtypes.csv')['dtypes']\n",
    "bus = pd.read_csv(\"../data/chi_bus_cleaned.csv\",dtype=df_types.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_naics(df_value, naics):\n",
    "    \n",
    "    \"\"\"\n",
    "    filter provided dataframe for naics codes. \n",
    "    mean to be used in df.apply() \n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    for i in naics:\n",
    "        \n",
    "        naics_length = len(i)\n",
    "        truncated_naics = df_value[:naics_length]\n",
    "        if truncated_naics == i:\n",
    "            results.append(True)\n",
    "        else:\n",
    "            results.append(False)\n",
    "            \n",
    "    return any(results)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def business_search(years, naics_codes):\n",
    "    \n",
    "    \"\"\"\n",
    "    :years: list of integer years you would like to select out\n",
    "    :naics_codes: list of string naics codes you would like to select out,\n",
    "                will match only up to the length of the code provided\n",
    "    Returns: filtered dataframe of business data \n",
    "    \"\"\"\n",
    "    \n",
    "    assert(isinstance(years,list)), \"\\\n",
    "        years argument must be of type list\"\n",
    "    \n",
    "    assert(all(element for element in [isinstance(i,int) for i in years])), \"\\\n",
    "        all years must be of type int\"\n",
    "    \n",
    "    assert(isinstance(naics_codes,list)), \"\\\n",
    "        naics_code argument must be of type list\"\n",
    "    \n",
    "    assert(all(element for element in [isinstance(i,str) for i in naics_codes])), \"\\\n",
    "        all naics_codes must be of type str\"\n",
    "    \n",
    "    df_types = pd.read_csv('../data/dtypes.csv')['dtypes']\n",
    "    bus = pd.read_csv(\"../data/chi_bus_cleaned.csv\",dtype=df_types.to_dict())\n",
    "    \n",
    "    bus = bus[bus['primary_naics_code'].apply(parse_naics, args=[naics_codes])]\n",
    "    \n",
    "    return bus[bus['year'].isin(years)]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus = business_search([2013,2015,2016], ['445110','335'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013    1518\n",
       "2015    1203\n",
       "2016    1034\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Understanding year distribution \n",
    "\n",
    "bus['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(767, 23)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering for 2016 and 2017\n",
    "\n",
    "groc_2016 = groc[groc['year']==2016]\n",
    "groc_2017 = groc[groc['year']==2017]\n",
    "\n",
    "# Concatenating 2016 and 2017 samples\n",
    "\n",
    "demand = pd.merge(left=groc_2017, right=groc_2016, left_on='abi', right_on='abi')\n",
    "demand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing additional less-useful features\n",
    "\n",
    "demand.drop(['primary_naics_code_y','company_y','year_y','business_status_code_y',\n",
    "            'company_holding_status_y','census_tract_y','year_established_y',\n",
    "            'company_y','year_y','business_status_code_y',\n",
    "            'latitude_y','longitude_y'], inplace=True, axis=1)\n",
    "\n",
    "cols = [demand.columns[i].replace(\"_x\",\"_2017\").replace(\"_y\",\"_2016\") for i in range(len(demand.columns))]\n",
    "replacing = {i:j for (i,j) in zip(demand.columns,cols)}\n",
    "demand.rename(columns=replacing, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to graph db\n",
    "\n",
    "uri = \"bolt://localhost:7687\"\n",
    "graph = Graph(uri, auth=(\"neo4j\", \"password\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling out coordinates for each store\n",
    "\n",
    "coordinates = list(zip(demand[\"longitude_2017\"],demand[\"latitude_2017\"]))\n",
    "\n",
    "# Pulling neighborhood polygons\n",
    "with open('dicts/neighborhood_polys.json','r') as f:\n",
    "    neighborhoods = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrisolen/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# Loading average property value for the neighborhood in which the stores is located\n",
    "\n",
    "demand['neighborhood_avg_property_value'] = np.nan\n",
    "\n",
    "outside_city = []\n",
    "\n",
    "for i in range(len(coordinates)):\n",
    "\n",
    "    point_district = utilities.point_lookup(neighborhoods,coordinates[i])\n",
    "    \n",
    "    try:\n",
    "        result = float(dict(pd.DataFrame(graph.run('match (a:neighborhood) where a.name = \"{}\" return a'.format(point_district)). \\\n",
    "                            to_table()).iloc[0,0])['avg_property_value'])\n",
    "        ## coordinates and df indices should be the same ## \n",
    "        demand['neighborhood_avg_property_value'].iloc[i] = result\n",
    "        \n",
    "    except:\n",
    "        outside_city.append((i, coordinates[i]))\n",
    "     \n",
    "    \n",
    "    \n",
    "for i in range(len(outside_city)): # for the few coordinates that lie just outside the city\n",
    "    \n",
    "    point_district = utilities.closest_to(neighborhoods,outside_city[i][1])\n",
    "    \n",
    "    result = float(dict(pd.DataFrame(graph.run('match (a:neighborhood) where a.name = \"{}\" return a'.format(point_district)). \\\n",
    "                            to_table()).iloc[0,0])['avg_property_value'])\n",
    "    \n",
    "    \n",
    "    demand['neighborhood_avg_property_value'].iloc[outside_city[i][0]] = result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading number of property crimes per neighborhood into demand model for each store\n",
    "\n",
    "demand['neighborhood_property_crimes'] = np.nan\n",
    "\n",
    "outside_city = []\n",
    "\n",
    "for i in range(len(coordinates)):\n",
    "\n",
    "    point_district = utilities.point_lookup(neighborhoods,coordinates[i])\n",
    "    \n",
    "    try:\n",
    "        result = float(dict(pd.DataFrame(graph.run('match (a:neighborhood) where a.name = \"{}\" return a'.format(point_district)). \\\n",
    "                            to_table()).iloc[0,0])['n_property_crimes'])\n",
    "        \n",
    "        ## coordinates and df indices should be the same ## \n",
    "        demand['neighborhood_property_crimes'].iloc[i] = result\n",
    "        \n",
    "    except:\n",
    "        outside_city.append((i, coordinates[i]))\n",
    "     \n",
    "    \n",
    "for i in range(len(outside_city)): # for the few coordinates that lie just outside the city\n",
    "    \n",
    "    point_district = utilities.closest_to(neighborhoods,outside_city[i][1])\n",
    "    \n",
    "    result = float(dict(pd.DataFrame(graph.run('match (a:neighborhood) where a.name = \"{}\" return a'.format(point_district)). \\\n",
    "                            to_table()).iloc[0,0])['n_property_crimes'])\n",
    "    \n",
    "    \n",
    "    demand['neighborhood_property_crimes'].iloc[outside_city[i][0]] = result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading average property values of neighborhoods surrounding the neighborhood of the given store\n",
    "\n",
    "demand['surrounding_neighborhood_avg_property_value'] = np.nan\n",
    "\n",
    "outside_city = []\n",
    "\n",
    "for i in range(len(coordinates)):\n",
    "\n",
    "    point_district = utilities.point_lookup(neighborhoods,coordinates[i])\n",
    "    \n",
    "    try:\n",
    "        result = pd.DataFrame(graph.run('match (a:neighborhood)-[:NEXT_TO]->(b) where a.name = \"{}\" return b'.format(point_district)). \\\n",
    "                            to_table())\n",
    "\n",
    "        n_next_door = len(result[0])\n",
    "\n",
    "        neighboring_means = []\n",
    "\n",
    "        for j in range(n_next_door):\n",
    "            neighboring_mean = float(dict(result[0][j])['avg_property_value'])\n",
    "            neighboring_means.append(neighboring_mean)\n",
    "            \n",
    "        surrounding_mean = np.nanmean(neighboring_means)\n",
    "        \n",
    "        ## coordinates and df indices should be the same ## \n",
    "        demand['surrounding_neighborhood_avg_property_value'].iloc[i] = surrounding_mean\n",
    "            \n",
    "    except:\n",
    "        outside_city.append((i, coordinates[i]))\n",
    "     \n",
    "    \n",
    "    \n",
    "for i in range(len(outside_city)): # for the few coordinates that lie just outside the city\n",
    "    \n",
    "    point_district = utilities.closest_to(neighborhoods,outside_city[i][1])\n",
    "    \n",
    "    result = pd.DataFrame(graph.run('match (a:neighborhood)-[:NEXT_TO]->(b) where a.name = \"{}\" return b'.format(point_district)). \\\n",
    "                            to_table())\n",
    "\n",
    "    n_next_door = len(result[0])\n",
    "\n",
    "    neighboring_means = []\n",
    "\n",
    "    for i in range(n_next_door):\n",
    "        neighboring_mean = float(dict(result[0][i])['avg_property_value'])\n",
    "        neighboring_means.append(neighboring_mean)\n",
    "        \n",
    "    surrounding_mean = np.nanmean(neighboring_means)\n",
    "    \n",
    "    demand['surrounding_neighborhood_avg_property_value'].iloc[outside_city[i][0]] = surrounding_mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading number of property crimes of neighborhoods surrounding the neighborhood of the given store\n",
    "\n",
    "demand['surrounding_neighborhood_property_crimes'] = np.nan\n",
    "\n",
    "outside_city = []\n",
    "\n",
    "for i in range(len(coordinates)):\n",
    "\n",
    "    point_district = utilities.point_lookup(neighborhoods,coordinates[i])\n",
    "\n",
    "    try:\n",
    "        result = pd.DataFrame(graph.run('match (a:neighborhood)-[:NEXT_TO]->(b) where a.name = \"{}\" return b'.format(point_district)). \\\n",
    "                            to_table())\n",
    "\n",
    "        n_next_door = len(result[0])\n",
    "\n",
    "        neighboring_means = []\n",
    "\n",
    "        for j in range(n_next_door):\n",
    "            neighboring_mean = float(dict(result[0][j])['n_property_crimes'])\n",
    "            neighboring_means.append(neighboring_mean)\n",
    "            \n",
    "        surrounding_mean = np.nanmean(neighboring_means)\n",
    "        \n",
    "        ## coordinates and df indices should be the same ## \n",
    "        demand['surrounding_neighborhood_property_crimes'].iloc[i] = surrounding_mean\n",
    "            \n",
    "    except:\n",
    "        outside_city.append((i, coordinates[i]))\n",
    "        \n",
    "    \n",
    "for i in range(len(outside_city)): # for the few coordinates that lie just outside the city\n",
    "    \n",
    "    point_district = utilities.closest_to(neighborhoods,outside_city[i][1])\n",
    "    \n",
    "    result = pd.DataFrame(graph.run('match (a:neighborhood)-[:NEXT_TO]->(b) where a.name = \"{}\" return b'.format(point_district)). \\\n",
    "                            to_table())\n",
    "\n",
    "    n_next_door = len(result[0])\n",
    "\n",
    "    neighboring_means = []\n",
    "\n",
    "    for i in range(n_next_door):\n",
    "        neighboring_mean = float(dict(result[0][i])['n_property_crimes'])\n",
    "        neighboring_means.append(neighboring_mean)\n",
    "        \n",
    "    surrounding_mean = np.nanmean(neighboring_means)\n",
    "    \n",
    "    demand['surrounding_neighborhood_property_crimes'].iloc[outside_city[i][0]] = surrounding_mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least squares model for 'D' component of objective function:\n",
    "\n",
    "D_demand = demand[(demand['sales_volume_location_2017'].notna()) &\n",
    "               (demand['sales_volume_location_2016'].notna()) &\n",
    "               (demand['neighborhood_property_crimes'].notna()) &\n",
    "               (demand['neighborhood_avg_property_value'].notna()) &\n",
    "               (demand['surrounding_neighborhood_avg_property_value'].notna()) &\n",
    "               (demand['surrounding_neighborhood_property_crimes'].notna())]\n",
    "\n",
    "D_demand_features = [\"sales_volume_location_2016\",\"neighborhood_avg_property_value\",\n",
    "                     \"neighborhood_property_crimes\",\n",
    "           \"surrounding_neighborhood_avg_property_value\",\"surrounding_neighborhood_property_crimes\"]\n",
    "\n",
    "D_X = np.array(D_demand[D_demand_features])\n",
    "D_y = np.array(D_demand[\"sales_volume_location_2017\"])\n",
    "\n",
    "\n",
    "# Least squares model for 'L' component of objective functon\n",
    "\n",
    "L_demand = demand[(demand['sales_volume_location_2017'].notna()) &\n",
    "               (demand['neighborhood_property_crimes'].notna()) &\n",
    "               (demand['neighborhood_avg_property_value'].notna()) &\n",
    "               (demand['surrounding_neighborhood_avg_property_value'].notna()) &\n",
    "               (demand['surrounding_neighborhood_property_crimes'].notna())]\n",
    "\n",
    "L_demand_features = [\"neighborhood_avg_property_value\",\n",
    "                     \"neighborhood_property_crimes\",\n",
    "           \"surrounding_neighborhood_avg_property_value\",\"surrounding_neighborhood_property_crimes\"]\n",
    "\n",
    "L_X = np.array(L_demand[L_demand_features])\n",
    "L_y = np.array(L_demand[\"sales_volume_location_2017\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_lr = LinearRegression()\n",
    "\n",
    "D_model = D_lr.fit(D_X,D_y)\n",
    "\n",
    "L_lr = LinearRegression()\n",
    "\n",
    "L_model = L_lr.fit(L_X,L_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9317133788087207,\n",
       " -0.05389048407535676,\n",
       " -0.21656957369296354,\n",
       " 0.031990880285334006,\n",
       " 0.2202127995619555]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_coef = list(D_model.coef_)\n",
    "D_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.2547677851422151,\n",
       " -0.5263550451979571,\n",
       " 1.1614176431445236,\n",
       " -2.0225396857646305]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_coef = list(L_model.coef_)\n",
    "L_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as txt file\n",
    "\n",
    "D_model_params = [D_demand_features, D_coef]\n",
    "\n",
    "with open('opt_variables/D_demand_coef.txt', 'w') as model_text:\n",
    "    for listitem in D_model_params:\n",
    "        model_text.write('%s\\n' % listitem)\n",
    "        \n",
    "        # save as txt file\n",
    "\n",
    "L_model_params = [L_demand_features, L_coef]\n",
    "\n",
    "with open('opt_variables/L_demand_coef.txt', 'w') as model_text:\n",
    "    for listitem in L_model_params:\n",
    "        model_text.write('%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
