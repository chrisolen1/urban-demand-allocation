{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import utilities\n",
    "import json\n",
    "\n",
    "from py2neo import Graph\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrisolen/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (2,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1144876, 12)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cols=['year',\n",
    " 'abi',\n",
    " 'ticker',\n",
    " 'company',\n",
    " 'address_line_1',\n",
    " 'city',\n",
    " 'zipcode',\n",
    " 'location_employee_size_code',\n",
    " 'location_sales_volume_code',\n",
    " 'primary_naics_code',\n",
    " 'sic_code',\n",
    " 'sic6_descriptions_sic',\n",
    " 'business_status_code',\n",
    " 'office_size_code',\n",
    " 'company_holding_status',\n",
    " 'parent_employee_size_code',\n",
    " 'parent_sales_volume_code',\n",
    " 'census_tract',\n",
    " 'cbsa_code',\n",
    " 'year_established',\n",
    " 'employee_size_location',\n",
    " 'sales_volume_location',\n",
    " 'parent_actual_employee_size',\n",
    " 'parent_actual_sales_volume',\n",
    " 'latitude',\n",
    " 'longitude']\n",
    "\n",
    "bus = pd.read_csv(\"../data/chi_bus.csv\", sep='\\t', names=cols)\n",
    "\n",
    "# Filtering for useful features\n",
    "\n",
    "bus = bus.loc[:,['abi','primary_naics_code','company','year','business_status_code','company_holding_status',\n",
    "           'census_tract','year_established',\n",
    "           'employee_size_location','sales_volume_location',\n",
    "           'latitude','longitude']]\n",
    "bus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    1034553\n",
       "2     101871\n",
       "3       4241\n",
       "1       4211\n",
       "Name: business_status_code, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Understanding business status code\n",
    "\n",
    "\"\"\"\n",
    "Business Status Code:\n",
    "\n",
    "1: Headquarter\n",
    "2: Branch\n",
    "3: Subsidiary\n",
    "9: Single Location\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "bus['business_status_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1144164\n",
       "False        712\n",
       "Name: company_holding_status, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Understanding business status holding\n",
    "\n",
    "\"\"\"\n",
    "Business Status Holding:\n",
    "\n",
    "I'm gonna assume the 712 are publicly traded and the others aren't?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "bus['company_holding_status'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1144164\n",
       "False        712\n",
       "Name: company_holding_status, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Understanding company holding status\n",
    "\n",
    "bus['company_holding_status'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1143647\n",
       "True        1229\n",
       "Name: primary_naics_code, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many samples don't have naics codes?\n",
    "\n",
    "bus['primary_naics_code'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove naics code nulls and convert to string\n",
    "\n",
    "bus = bus[~bus['primary_naics_code'].isna()]\n",
    "bus['primary_naics_code'] = (bus['primary_naics_code'].astype(int)).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10469, 12)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering for naics codes\n",
    "\n",
    "\"\"\"\n",
    "Grocery Store-Related NAICS Codes:\n",
    "\n",
    "NAICS CODE 445110: Supermarkets and Other Grocery (except Convenience)\n",
    "NAICS CODE 447110: Gasoline Stations with Convenience Stores\n",
    "NAICS CODE 445120: Convenience Stores\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#groc = bus[(bus['primary_naics_code'].str.contains('445110')) | (bus['primary_naics_code'].str.contains('447110')) | (bus['primary_naics_code'].str.contains('445120'))]\n",
    "groc = bus[(bus['primary_naics_code'].str.contains('445110'))]\n",
    "groc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013    1430\n",
       "2014    1257\n",
       "2012    1213\n",
       "2010    1125\n",
       "2015    1122\n",
       "2011    1109\n",
       "2009    1107\n",
       "2016     964\n",
       "2017     826\n",
       "2018     316\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Understanding year distribution \n",
    "\n",
    "groc['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(767, 23)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering for 2016 and 2017\n",
    "\n",
    "groc_2016 = groc[groc['year']==2016]\n",
    "groc_2017 = groc[groc['year']==2017]\n",
    "\n",
    "# Concatenating 2016 and 2017 samples\n",
    "\n",
    "demand = pd.merge(left=groc_2017, right=groc_2016, left_on='abi', right_on='abi')\n",
    "demand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing additional less-useful features\n",
    "\n",
    "demand.drop(['primary_naics_code_y','company_y','year_y','business_status_code_y',\n",
    "            'company_holding_status_y','census_tract_y','year_established_y',\n",
    "            'company_y','year_y','business_status_code_y',\n",
    "            'latitude_y','longitude_y'], inplace=True, axis=1)\n",
    "\n",
    "cols = [demand.columns[i].replace(\"_x\",\"_2017\").replace(\"_y\",\"_2016\") for i in range(len(demand.columns))]\n",
    "replacing = {i:j for (i,j) in zip(demand.columns,cols)}\n",
    "demand.rename(columns=replacing, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to graph db\n",
    "\n",
    "uri = \"bolt://localhost:7687\"\n",
    "graph = Graph(uri, auth=(\"neo4j\", \"password\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling out coordinates for each store\n",
    "\n",
    "coordinates = list(zip(demand[\"longitude_2017\"],demand[\"latitude_2017\"]))\n",
    "\n",
    "# Pulling neighborhood polygons\n",
    "with open('dicts/neighborhood_polys.json','r') as f:\n",
    "    neighborhoods = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrisolen/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# Loading average property value for the neighborhood in which the stores is located\n",
    "\n",
    "demand['neighborhood_avg_property_value'] = np.nan\n",
    "\n",
    "outside_city = []\n",
    "\n",
    "for i in range(len(coordinates)):\n",
    "\n",
    "    point_district = utilities.point_lookup(neighborhoods,coordinates[i])\n",
    "    \n",
    "    try:\n",
    "        result = float(dict(pd.DataFrame(graph.run('match (a:neighborhood) where a.name = \"{}\" return a'.format(point_district)). \\\n",
    "                            to_table()).iloc[0,0])['avg_property_value'])\n",
    "        ## coordinates and df indices should be the same ## \n",
    "        demand['neighborhood_avg_property_value'].iloc[i] = result\n",
    "        \n",
    "    except:\n",
    "        outside_city.append((i, coordinates[i]))\n",
    "     \n",
    "    \n",
    "    \n",
    "for i in range(len(outside_city)): # for the few coordinates that lie just outside the city\n",
    "    \n",
    "    point_district = utilities.closest_to(neighborhoods,outside_city[i][1])\n",
    "    \n",
    "    result = float(dict(pd.DataFrame(graph.run('match (a:neighborhood) where a.name = \"{}\" return a'.format(point_district)). \\\n",
    "                            to_table()).iloc[0,0])['avg_property_value'])\n",
    "    \n",
    "    \n",
    "    demand['neighborhood_avg_property_value'].iloc[outside_city[i][0]] = result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading number of property crimes per neighborhood into demand model for each store\n",
    "\n",
    "demand['neighborhood_property_crimes'] = np.nan\n",
    "\n",
    "outside_city = []\n",
    "\n",
    "for i in range(len(coordinates)):\n",
    "\n",
    "    point_district = utilities.point_lookup(neighborhoods,coordinates[i])\n",
    "    \n",
    "    try:\n",
    "        result = float(dict(pd.DataFrame(graph.run('match (a:neighborhood) where a.name = \"{}\" return a'.format(point_district)). \\\n",
    "                            to_table()).iloc[0,0])['n_property_crimes'])\n",
    "        \n",
    "        ## coordinates and df indices should be the same ## \n",
    "        demand['neighborhood_property_crimes'].iloc[i] = result\n",
    "        \n",
    "    except:\n",
    "        outside_city.append((i, coordinates[i]))\n",
    "     \n",
    "    \n",
    "for i in range(len(outside_city)): # for the few coordinates that lie just outside the city\n",
    "    \n",
    "    point_district = utilities.closest_to(neighborhoods,outside_city[i][1])\n",
    "    \n",
    "    result = float(dict(pd.DataFrame(graph.run('match (a:neighborhood) where a.name = \"{}\" return a'.format(point_district)). \\\n",
    "                            to_table()).iloc[0,0])['n_property_crimes'])\n",
    "    \n",
    "    \n",
    "    demand['neighborhood_property_crimes'].iloc[outside_city[i][0]] = result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading average property values of neighborhoods surrounding the neighborhood of the given store\n",
    "\n",
    "demand['surrounding_neighborhood_avg_property_value'] = np.nan\n",
    "\n",
    "outside_city = []\n",
    "\n",
    "for i in range(len(coordinates)):\n",
    "\n",
    "    point_district = utilities.point_lookup(neighborhoods,coordinates[i])\n",
    "    \n",
    "    try:\n",
    "        result = pd.DataFrame(graph.run('match (a:neighborhood)-[:NEXT_TO]->(b) where a.name = \"{}\" return b'.format(point_district)). \\\n",
    "                            to_table())\n",
    "\n",
    "        n_next_door = len(result[0])\n",
    "\n",
    "        neighboring_means = []\n",
    "\n",
    "        for j in range(n_next_door):\n",
    "            neighboring_mean = float(dict(result[0][j])['avg_property_value'])\n",
    "            neighboring_means.append(neighboring_mean)\n",
    "            \n",
    "        surrounding_mean = np.nanmean(neighboring_means)\n",
    "        \n",
    "        ## coordinates and df indices should be the same ## \n",
    "        demand['surrounding_neighborhood_avg_property_value'].iloc[i] = surrounding_mean\n",
    "            \n",
    "    except:\n",
    "        outside_city.append((i, coordinates[i]))\n",
    "     \n",
    "    \n",
    "    \n",
    "for i in range(len(outside_city)): # for the few coordinates that lie just outside the city\n",
    "    \n",
    "    point_district = utilities.closest_to(neighborhoods,outside_city[i][1])\n",
    "    \n",
    "    result = pd.DataFrame(graph.run('match (a:neighborhood)-[:NEXT_TO]->(b) where a.name = \"{}\" return b'.format(point_district)). \\\n",
    "                            to_table())\n",
    "\n",
    "    n_next_door = len(result[0])\n",
    "\n",
    "    neighboring_means = []\n",
    "\n",
    "    for i in range(n_next_door):\n",
    "        neighboring_mean = float(dict(result[0][i])['avg_property_value'])\n",
    "        neighboring_means.append(neighboring_mean)\n",
    "        \n",
    "    surrounding_mean = np.nanmean(neighboring_means)\n",
    "    \n",
    "    demand['surrounding_neighborhood_avg_property_value'].iloc[outside_city[i][0]] = surrounding_mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading number of property crimes of neighborhoods surrounding the neighborhood of the given store\n",
    "\n",
    "demand['surrounding_neighborhood_property_crimes'] = np.nan\n",
    "\n",
    "outside_city = []\n",
    "\n",
    "for i in range(len(coordinates)):\n",
    "\n",
    "    point_district = utilities.point_lookup(neighborhoods,coordinates[i])\n",
    "\n",
    "    try:\n",
    "        result = pd.DataFrame(graph.run('match (a:neighborhood)-[:NEXT_TO]->(b) where a.name = \"{}\" return b'.format(point_district)). \\\n",
    "                            to_table())\n",
    "\n",
    "        n_next_door = len(result[0])\n",
    "\n",
    "        neighboring_means = []\n",
    "\n",
    "        for j in range(n_next_door):\n",
    "            neighboring_mean = float(dict(result[0][j])['n_property_crimes'])\n",
    "            neighboring_means.append(neighboring_mean)\n",
    "            \n",
    "        surrounding_mean = np.nanmean(neighboring_means)\n",
    "        \n",
    "        ## coordinates and df indices should be the same ## \n",
    "        demand['surrounding_neighborhood_property_crimes'].iloc[i] = surrounding_mean\n",
    "            \n",
    "    except:\n",
    "        outside_city.append((i, coordinates[i]))\n",
    "        \n",
    "    \n",
    "for i in range(len(outside_city)): # for the few coordinates that lie just outside the city\n",
    "    \n",
    "    point_district = utilities.closest_to(neighborhoods,outside_city[i][1])\n",
    "    \n",
    "    result = pd.DataFrame(graph.run('match (a:neighborhood)-[:NEXT_TO]->(b) where a.name = \"{}\" return b'.format(point_district)). \\\n",
    "                            to_table())\n",
    "\n",
    "    n_next_door = len(result[0])\n",
    "\n",
    "    neighboring_means = []\n",
    "\n",
    "    for i in range(n_next_door):\n",
    "        neighboring_mean = float(dict(result[0][i])['n_property_crimes'])\n",
    "        neighboring_means.append(neighboring_mean)\n",
    "        \n",
    "    surrounding_mean = np.nanmean(neighboring_means)\n",
    "    \n",
    "    demand['surrounding_neighborhood_property_crimes'].iloc[outside_city[i][0]] = surrounding_mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least squares model for 'D' component of objective function:\n",
    "\n",
    "D_demand = demand[(demand['sales_volume_location_2017'].notna()) &\n",
    "               (demand['sales_volume_location_2016'].notna()) &\n",
    "               (demand['neighborhood_property_crimes'].notna()) &\n",
    "               (demand['neighborhood_avg_property_value'].notna()) &\n",
    "               (demand['surrounding_neighborhood_avg_property_value'].notna()) &\n",
    "               (demand['surrounding_neighborhood_property_crimes'].notna())]\n",
    "\n",
    "D_demand_features = [\"sales_volume_location_2016\",\"neighborhood_avg_property_value\",\n",
    "                     \"neighborhood_property_crimes\",\n",
    "           \"surrounding_neighborhood_avg_property_value\",\"surrounding_neighborhood_property_crimes\"]\n",
    "\n",
    "D_X = np.array(D_demand[D_demand_features])\n",
    "D_y = np.array(D_demand[\"sales_volume_location_2017\"])\n",
    "\n",
    "\n",
    "# Least squares model for 'L' component of objective functon\n",
    "\n",
    "L_demand = demand[(demand['sales_volume_location_2017'].notna()) &\n",
    "               (demand['neighborhood_property_crimes'].notna()) &\n",
    "               (demand['neighborhood_avg_property_value'].notna()) &\n",
    "               (demand['surrounding_neighborhood_avg_property_value'].notna()) &\n",
    "               (demand['surrounding_neighborhood_property_crimes'].notna())]\n",
    "\n",
    "L_demand_features = [\"neighborhood_avg_property_value\",\n",
    "                     \"neighborhood_property_crimes\",\n",
    "           \"surrounding_neighborhood_avg_property_value\",\"surrounding_neighborhood_property_crimes\"]\n",
    "\n",
    "L_X = np.array(L_demand[L_demand_features])\n",
    "L_y = np.array(L_demand[\"sales_volume_location_2017\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_lr = LinearRegression()\n",
    "\n",
    "D_model = D_lr.fit(D_X,D_y)\n",
    "\n",
    "L_lr = LinearRegression()\n",
    "\n",
    "L_model = L_lr.fit(L_X,L_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9317133788087207,\n",
       " -0.05389048407535676,\n",
       " -0.21656957369296354,\n",
       " 0.031990880285334006,\n",
       " 0.2202127995619555]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_coef = list(D_model.coef_)\n",
    "D_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.2547677851422151,\n",
       " -0.5263550451979571,\n",
       " 1.1614176431445236,\n",
       " -2.0225396857646305]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_coef = list(L_model.coef_)\n",
    "L_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as txt file\n",
    "\n",
    "D_model_params = [D_demand_features, L_coef]\n",
    "\n",
    "with open('D_demand_coef.txt', 'w') as model_text:\n",
    "    for listitem in D_model_params:\n",
    "        model_text.write('%s\\n' % listitem)\n",
    "        \n",
    "        # save as txt file\n",
    "\n",
    "L_model_params = [L_demand_features, L_coef]\n",
    "\n",
    "with open('L_demand_coef.txt', 'w') as model_text:\n",
    "    for listitem in L_model_params:\n",
    "        model_text.write('%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
